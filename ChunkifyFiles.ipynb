{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "44b2ef491ffa834b1acb4c2cfdc4251b",
     "grade": false,
     "grade_id": "cell-08a6a4edb9d24de3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You have a file that needs to be divided into `n` chunks. While it would be straightforward to split the file into equal-bytes sizes and then write those chunks to file, you cannot write any incomplete lines to the files. This means that all of the `n` files that you create must have **no truncated lines**. If a split of a certain byte-size would result in a truncated line, then you can back off and only write the previous complete line. You can save the rest of it for the next chunk.\n",
    "\n",
    "You can download [Metamorphosis, by Franz Kafka](https://storage.googleapis.com/class-notes-181217.appspot.com/pg5200.txt) as the sample text. The file is of size 139055 bytes. Splitting into three pieces gives the following files and their respective sizes:\n",
    "\n",
    "   |size | filename         |\n",
    "   |-----| -----------------| \n",
    "|46310|pg5200.txt_00.txt|\n",
    "|46334|pg5200.txt_01.txt|\n",
    "|46411|pg5200.txt_02.txt|\n",
    "\n",
    "\n",
    "The last line of the `pg5200.txt_00.txt` is the following:\n",
    "\n",
    "    her, she hurried out again and even turned the key in the lock so\n",
    "    \n",
    "The last line of the `pg5200.txt_01.txt` is the following:\n",
    "\n",
    "    there.  He, fortunately, would usually see no more than the object\n",
    "    \n",
    "As a final hint, splitting the same file into eight parts gives the following:\n",
    "\n",
    "\n",
    "|size | filename       |\n",
    "|-----|----------------|\n",
    "|17321|pg5200.txt_00.txt|\n",
    "|17376|pg5200.txt_01.txt|\n",
    "|17409|pg5200.txt_02.txt|\n",
    "|17354|pg5200.txt_03.txt|\n",
    "|17445|pg5200.txt_04.txt|\n",
    "|17332|pg5200.txt_05.txt|\n",
    "|17381|pg5200.txt_06.txt|\n",
    "|17437|pg5200.txt_07.txt|\n",
    "\n",
    "\n",
    "You should think about making your file sizes as uniform as possible. Otherwise, for a very long file, the last file may be inordinately large, as compared to the others. Your algorithm should pass through the file exactly once. If possible, you also want to minimize how much you move the file pointer around in the file.   You should ensure that your code produces the file sizes that are indicated for each of the cases shown above.\n",
    "\n",
    "* Hint: Use ``wb`` as the file write mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "53363512423b4fddcd79e02838a0f956",
     "grade": false,
     "grade_id": "cell-e91a2afd8181d503",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# def getfilesize(filename):\n",
    "#     with open(filename,\"rb\") as fr:\n",
    "#         fr.seek(0,2) # move to end of the file\n",
    "#         size=fr.tell() + 1\n",
    "#         print(\"getfilesize: size: %s\" % size)\n",
    "#         return fr.tell()\n",
    "\n",
    "def split_by_n(fname,n=3):\n",
    "    assert isinstance(n,int),'input number of chunks is not a integer'\n",
    "    assert isinstance(fname,str),'input file name is not a string'\n",
    "#     with open(fname, 'rb') as mfile:\n",
    "#         content = bytearray(os.path.getsize(fname))\n",
    "#         mfile.readinto(content)\n",
    "#         chunk_size = os.path.getsize(fname)/n\n",
    "#         for counter, i in enumerate(range(0, len(content),int(chunk_size))):\n",
    "#             with open(fname[counter], 'wb') as f:\n",
    "#                 f.write(content[i: i + int(chunk_size)])\n",
    "    \n",
    "    file_size = os.path.getsize(fname)\n",
    "    with open(fname,'r') as file:\n",
    "        line = file.readline()\n",
    "        sen_list = []\n",
    "        while line:\n",
    "            sen_list.append(line)\n",
    "            line = file.readline()\n",
    "    chunk_size = file_size/n\n",
    "    size_keeper = 0\n",
    "    line_num = 0\n",
    "    for num in range(n):\n",
    "        new_file = fname + '_' + str(num).zfill(2) + '.txt'\n",
    "        with open(new_file,'wb') as file:\n",
    "            while (size_keeper + len(sen_list[line_num])) <= (num+1) * chunk_size:\n",
    "                file.write(sen_list[line_num].encode())\n",
    "                size_keeper += len(sen_list[line_num])\n",
    "                line_num += 1\n",
    "                if line_num >= len(sen_list):\n",
    "                    break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_n('Metamorphosis.txt',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c5ac3c26e027cc9c3f2b6cbaffd95135",
     "grade": true,
     "grade_id": "cell-777fec16a5490c1e",
     "locked": true,
     "points": 30,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
